---
title: "Introduction to Statistical Learning"
author: "Melina Much, Ph.D. Candidate"
date: "8/23/2021"
output: slidy_presentation
---

## Statistical Learning - Foundations

- In any statistical framework or paradigm, we are looking to *learn from data* about the world around us. 

- We as researchers will formulate hypotheses, or have intuitions about relationships that exist in a given dataset.

## Kinds of Variables

- This knowledge helps specify **input variables** (which we call independent variables or predictors), and **output variables** (which we call dependent variables). 
    
- Our input variables we believe have an influence or effect our output variables. 

## Some Notation

- We often represent our independent/input/predictor variables as $X$ and our output/dependent variables as $Y$.

- In most cases we have a handful of $X's$ and one $Y$.

- We assume there is a relationship between these variables (our inputs and outputs).

- We call this relationship $f$. In most cases we don't know what $f$ is.

- Therefore the relationship between our inputs and outputs can be represented as: 

$$Y = f(x) + \epsilon$$
- In $Y = f(x) + \epsilon$, $\epsilon$ represents a random error term that is independent of $X$.

## Your Job as a Statistical Researcher

- In order to glean something from these variables, we have to make educated guesses about the *form* of the relationship between $X$ and $Y$.

**The foundation of statistical learning is therefore specifying the functional form $f$ in the relationship between $X$ and $Y$. In other words $f$ is the *systematic* information that $X$ provides about $Y$**

- You have many options. Our job is to help prime you on how to choose an estimate of $f$, which we will call $\hat{f}$, and interpret $Y = \hat{f}(x) + \epsilon$.

- Being able to specify the $\hat{f}$ well allows you to make good: *inferences* about your data (how $X$ relates to $Y$), and *predictions* about new data (what would a new value of $Y$ likely if we knew $X$).

## For Example

- Say we are answering one of the earliest physics questions about ball trajectory. 

**We want to know how the strength of a person (input) relates to how far they can throw a ball (output). What is still left to specify?**

- We can specify the functional form of the ball trajectory $\hat{f}$ differently based on our guesses on how balls travel through space. Does it immediately drop? Does it reach a peak height and drop from there? Does it take a curved trajectory down? Each of those are our different specifications of $\hat{f}$.

- Our specification of $\hat{f}$ will inherently change our guess of $Y$ how far the ball travels. That choice of $\hat{f}$ matters a ton!

## Errors

- There will inevitably be a difference between $f$ and our estimate $\hat{f}$.

- The difference between these two functions is our **reducible error.**

- We could specify $\hat{f}$ to get a better picutre of $Y$, therefore, that error is considered reducible.

- **Irreducible error** comes from the fact that $Y$ is also a function of $\epsilon$ and is independent of our specification of $f$.

- That means that regardless of how we specify $f$ we will always have some error!

 
## Model Building Goals

- Build and use statistical models that get rid of as much reducible error as possible.

- Balance the tradeoffs in model choice. 

    - The tradeoffs are with **accuracy** and **interpretability.**
    
    - Some models, particularly flexible machine learning algorithms are highly **accurate**, but the relationships
    between inputs and outputs remain unknown (are not **interpretable**) during the prediction process (black box models).

    - Some models, particularly those in the regression framework (like we will see today), where you specify a          functional form overtly, are highly **interpretable,** but are less **accurate.**


## A Tale of Two Data Forms

- When learning from our data we want to get as close as we can to understanding **causal relationships.** We want to know: does $X$ cause $Y$? Our ability to do that changes based on the kinds of data we have. 

- **Observational data** comes from measuring a sample of the population, where we are not looking to effect the respondents, and we are not manipulating their environment. We are simply looking to *observe.* This data will have **confounders,** or variables that influence $Y$ that are not $X$ that we are not accounting for in our modeling.

- **Experimental data** controls for external forces (variables hard to account for) by leveraging the benefits of random assignment. Experimental data has randomly assigned treatment and control groups, which alleviates the issues of confounders since the only functional difference between the groups is their arbitrary assignment into treatment or control.

- *Experiments allow us to address causality because you can isolate the treatment effect. Observational studies do not. Observational studies can look at **associations**but never directly make causal claims.*

- Our work will deal largely with observational data.

## Textbook Recommendations

- For a super intuitive way to frame statistical learning from regression all the way to machine learning look at the free [Introduction to Statistical Learning](https://link.springer.com/content/pdf/10.1007%2F978-1-0716-1418-1.pdf).

- For one of the best Social Science comprehensive approaches to uncertainty in Statistics, looking at both Bayesianism and Frequentism, see [Regression and Other Stories](https://www.amazon.com/Regression-Stories-Analytical-Methods-Research/dp/110702398X). Expensive, but worth it.





